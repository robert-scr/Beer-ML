# Environment Configuration for Beer Study Application
# Copy this file to .env and customize for your deployment

# OpenAI Configuration for LLM Predictor (Optional)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini

# Predictor Configuration
# Choose prediction method: 'similarity' or 'llm'
PREDICTOR_TYPE=similarity

# Frontend Configuration
# Update this with your laptop's IP address for network access
NEXT_PUBLIC_API_URL=http://10.100.91.169:5000
#NEXT_PUBLIC_API_URL=http://localhost:5000

# Backend Configuration
# Flask configuration
FLASK_ENV=production
FLASK_DEBUG=false

# Database Configuration
# SQLite database will be created automatically
DATABASE_PATH=beer_study.db

# Network Configuration
# Backend binds to all interfaces (0.0.0.0) by default
# Frontend can be configured to bind to specific host

# Usage Instructions:
# 1. Find your laptop's IP address: ip addr show | grep inet
# 2. Update NEXT_PUBLIC_API_URL with your IP
# 3. Copy this file to beer-ml-frontend/.env.local
# 4. Start backend: cd backend && ./start.sh
# 5. Start frontend: ./start-frontend.sh
# 6. Access from other devices: http://YOUR_IP:3000
